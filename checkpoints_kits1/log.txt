[13:58:03.678] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[13:58:04.128] No checkpoint or best model found. Starting training from scratch.
[13:58:04.129] 18375 iterations per epoch. 50000 total iterations.
[13:58:12.405] Iteration 1: Loss 0.9382
[13:58:29.888] Iteration 2: Loss 0.8877
[13:58:30.393] Iteration 3: Loss 0.8064
[13:58:30.891] Iteration 4: Loss 0.7151
[13:58:31.389] Iteration 5: Loss 0.6238
[13:58:38.453] Iteration 6: Loss 0.5487
[13:58:38.947] Iteration 7: Loss 0.4987
[13:58:39.464] Iteration 8: Loss 0.4564
[13:58:39.966] Iteration 9: Loss 0.4333
[13:58:51.132] Iteration 10: Loss 0.4071
[13:58:51.634] Iteration 11: Loss 0.3833
[13:58:52.135] Iteration 12: Loss 0.4317
[13:58:52.635] Iteration 13: Loss 0.3853
[13:58:58.795] Iteration 14: Loss 0.3619
[13:58:59.295] Iteration 15: Loss 0.3577
[13:58:59.801] Iteration 16: Loss 0.3818
[13:59:00.303] Iteration 17: Loss 0.3630
[13:59:05.991] Iteration 18: Loss 0.3563
[13:59:06.492] Iteration 19: Loss 0.3838
[13:59:06.991] Iteration 20: Loss 0.3600
[13:59:07.491] Iteration 21: Loss 0.3426
[13:59:08.029] Iteration 22: Loss 0.3419
[13:59:08.534] Iteration 23: Loss 0.3856
[13:59:09.036] Iteration 24: Loss 0.3557
[13:59:09.541] Iteration 25: Loss 0.3434
[13:59:14.815] Iteration 26: Loss 0.3851
[13:59:15.359] Iteration 27: Loss 0.3405
[13:59:15.889] Iteration 28: Loss 0.3401
[13:59:16.409] Iteration 29: Loss 0.3658
[13:59:16.915] Iteration 30: Loss 0.3324
[13:59:17.422] Iteration 31: Loss 0.3639
[13:59:17.929] Iteration 32: Loss 0.3610
[13:59:18.437] Iteration 33: Loss 0.3441
[13:59:26.080] Iteration 34: Loss 0.3531
[13:59:26.581] Iteration 35: Loss 0.3766
[13:59:27.089] Iteration 36: Loss 0.3538
[13:59:27.594] Iteration 37: Loss 0.3408
[13:59:28.101] Iteration 38: Loss 0.3447
[13:59:28.609] Iteration 39: Loss 0.3656
[13:59:29.115] Iteration 40: Loss 0.3386
[13:59:32.126] Iteration 41: Loss 0.3531
[13:59:35.293] Iteration 42: Loss 0.3574
[13:59:41.642] Iteration 43: Loss 0.3382
[13:59:42.147] Iteration 44: Loss 0.3349
[13:59:46.936] Iteration 45: Loss 0.3693
[13:59:47.441] Iteration 46: Loss 0.3441
[13:59:47.947] Iteration 47: Loss 0.3971
[13:59:48.453] Iteration 48: Loss 0.3475
[13:59:54.043] Iteration 49: Loss 0.3515
[13:59:54.544] Iteration 50: Loss 0.3401
[13:59:55.063] Iteration 51: Loss 0.3300
[13:59:55.571] Iteration 52: Loss 0.3516
[14:00:02.936] Iteration 53: Loss 0.3264
[14:00:03.438] Iteration 54: Loss 0.3508
[14:00:03.953] Iteration 55: Loss 0.3781
[14:00:04.471] Iteration 56: Loss 0.3617
[14:00:09.226] Iteration 57: Loss 0.3241
[14:00:09.737] Iteration 58: Loss 0.3357
[14:00:10.242] Iteration 59: Loss 0.3304
[14:00:10.753] Iteration 60: Loss 0.3353
[14:00:13.909] Iteration 61: Loss 0.3286
[14:00:22.809] Iteration 62: Loss 0.3373
[14:00:23.309] Iteration 63: Loss 0.3494
[14:00:23.817] Iteration 64: Loss 0.3624
[14:00:24.330] Iteration 65: Loss 0.3955
[14:00:24.843] Iteration 66: Loss 0.3466
[14:00:25.363] Iteration 67: Loss 0.3568
[14:00:25.875] Iteration 68: Loss 0.3384
[14:00:26.397] Iteration 69: Loss 0.3540
[14:00:37.930] Iteration 70: Loss 0.3875
[14:00:38.476] Iteration 71: Loss 0.3354
[14:00:38.993] Iteration 72: Loss 0.3286
[14:00:39.516] Iteration 73: Loss 0.3493
[14:00:40.028] Iteration 74: Loss 0.3489
[14:00:40.560] Iteration 75: Loss 0.3491
[14:00:41.084] Iteration 76: Loss 0.3674
[14:00:42.872] Iteration 77: Loss 0.2887
[14:00:48.251] Iteration 78: Loss 0.3269
[14:00:48.770] Iteration 79: Loss 0.3290
[14:00:49.295] Iteration 80: Loss 0.3708
[14:00:53.070] Iteration 81: Loss 0.3301
[14:00:53.583] Iteration 82: Loss 0.3097
[14:00:54.099] Iteration 83: Loss 0.3346
[14:00:54.610] Iteration 84: Loss 0.3007
[14:00:55.126] Iteration 85: Loss 0.3480
[14:01:04.857] Iteration 86: Loss 0.3426
[14:01:14.259] Iteration 87: Loss 0.3685
[14:01:14.764] Iteration 88: Loss 0.3631
[14:01:15.286] Iteration 89: Loss 0.3231
[14:01:15.799] Iteration 90: Loss 0.3518
[14:01:16.312] Iteration 91: Loss 0.2719
[14:01:16.824] Iteration 92: Loss 0.3435
[14:01:17.341] Iteration 93: Loss 0.3031
[14:01:18.668] Iteration 94: Loss 0.3398
[14:01:23.545] Iteration 95: Loss 0.3145
[14:01:30.299] Iteration 96: Loss 0.3022
[14:01:30.814] Iteration 97: Loss 0.3538
[14:01:31.331] Iteration 98: Loss 0.3349
[14:01:31.854] Iteration 99: Loss 0.3550
[14:01:32.374] Iteration 100: Loss 0.3456
[14:01:32.898] Iteration 101: Loss 0.3621
[14:01:33.432] Iteration 102: Loss 0.3379
[14:01:52.330] Iteration 103: Loss 0.2756
[14:01:52.856] Iteration 104: Loss 0.3431
[14:01:53.380] Iteration 105: Loss 0.3073
[14:01:53.927] Iteration 106: Loss 0.3270
[14:01:54.456] Iteration 107: Loss 0.2897
[14:01:55.006] Iteration 108: Loss 0.3462
[14:01:56.125] Iteration 109: Loss 0.3150
[14:01:56.648] Iteration 110: Loss 0.2914
[14:02:23.459] Iteration 111: Loss 0.3175
[14:02:23.966] Iteration 112: Loss 0.3543
[14:02:24.472] Iteration 113: Loss 0.3479
[14:02:24.978] Iteration 114: Loss 0.3340
[14:02:25.487] Iteration 115: Loss 0.3394
[14:02:25.998] Iteration 116: Loss 0.3420
[14:02:26.515] Iteration 117: Loss 0.2958
[14:02:27.037] Iteration 118: Loss 0.3526
[14:02:29.413] Iteration 119: Loss 0.3541
[14:02:29.923] Iteration 120: Loss 0.2998
[14:02:30.435] Iteration 121: Loss 0.3276
[14:02:30.953] Iteration 122: Loss 0.3249
[14:02:31.467] Iteration 123: Loss 0.3052
[14:02:31.986] Iteration 124: Loss 0.3111
[14:02:32.501] Iteration 125: Loss 0.3144
[14:02:33.016] Iteration 126: Loss 0.3210
[14:02:35.907] Iteration 127: Loss 0.3304
[14:02:57.837] Iteration 128: Loss 0.3524
[14:02:58.340] Iteration 129: Loss 0.3349
[14:02:58.848] Iteration 130: Loss 0.3510
[14:02:59.354] Iteration 131: Loss 0.3249
[14:02:59.907] Iteration 132: Loss 0.3298
[14:03:00.508] Iteration 133: Loss 0.3677
[14:03:01.062] Iteration 134: Loss 0.3661
[14:03:01.610] Iteration 135: Loss 0.3068
[14:03:11.799] Iteration 136: Loss 0.3523
[14:03:12.312] Iteration 137: Loss 0.3574
[14:03:12.824] Iteration 138: Loss 0.3260
[14:03:13.343] Iteration 139: Loss 0.3175
[14:03:13.862] Iteration 140: Loss 0.3625
[14:03:14.373] Iteration 141: Loss 0.3246
[14:03:14.886] Iteration 142: Loss 0.2934
[14:03:15.407] Iteration 143: Loss 0.2997
[14:03:34.877] Iteration 144: Loss 0.2512
[14:03:35.393] Iteration 145: Loss 0.3154
[14:03:35.903] Iteration 146: Loss 0.3606
[14:03:36.412] Iteration 147: Loss 0.3028
[14:03:36.930] Iteration 148: Loss 0.3544
[14:03:37.450] Iteration 149: Loss 0.3372
[14:03:37.976] Iteration 150: Loss 0.3555
[14:03:38.580] Iteration 151: Loss 0.3502
[14:03:56.569] Iteration 152: Loss 0.3070
[14:03:57.079] Iteration 153: Loss 0.3309
[14:03:57.591] Iteration 154: Loss 0.3196
[14:03:58.102] Iteration 155: Loss 0.3383
[14:03:58.622] Iteration 156: Loss 0.3249
[14:03:59.136] Iteration 157: Loss 0.3329
[14:03:59.652] Iteration 158: Loss 0.3225
[14:04:00.170] Iteration 159: Loss 0.2937
[14:04:09.371] Iteration 160: Loss 0.3516
[14:04:09.889] Iteration 161: Loss 0.3118
[14:04:10.431] Iteration 162: Loss 0.3000
[14:04:10.950] Iteration 163: Loss 0.3334
[14:04:11.476] Iteration 164: Loss 0.3542
[14:04:12.005] Iteration 165: Loss 0.3277
[14:04:15.246] Iteration 166: Loss 0.3529
[14:04:15.797] Iteration 167: Loss 0.3498
[14:04:23.008] Iteration 168: Loss 0.3478
[14:04:23.523] Iteration 169: Loss 0.3129
[14:04:24.066] Iteration 170: Loss 0.3283
[14:04:24.587] Iteration 171: Loss 0.3308
[14:04:25.138] Iteration 172: Loss 0.3076
[14:04:25.662] Iteration 173: Loss 0.3113
[14:04:28.693] Iteration 174: Loss 0.2894
[14:04:29.279] Iteration 175: Loss 0.3126
[14:04:44.006] Iteration 176: Loss 0.3291
[14:04:44.542] Iteration 177: Loss 0.2938
[14:04:56.609] Iteration 178: Loss 0.3478
[14:04:57.120] Iteration 179: Loss 0.3099
[14:04:57.633] Iteration 180: Loss 0.3406
[14:04:58.144] Iteration 181: Loss 0.3046
[14:04:58.658] Iteration 182: Loss 0.3450
[14:04:59.177] Iteration 183: Loss 0.3504
[14:04:59.924] Iteration 184: Loss 0.2495
[14:05:00.462] Iteration 185: Loss 0.2934
[14:05:04.643] Iteration 186: Loss 0.3468
[14:05:05.163] Iteration 187: Loss 0.3016
[14:05:05.683] Iteration 188: Loss 0.3017
[14:05:06.284] Iteration 189: Loss 0.3439
[14:05:13.893] Iteration 190: Loss 0.2778
[14:05:14.411] Iteration 191: Loss 0.2768
[14:05:14.928] Iteration 192: Loss 0.3416
[14:05:15.453] Iteration 193: Loss 0.2846
[14:05:15.979] Iteration 194: Loss 0.3311
[14:05:16.549] Iteration 195: Loss 0.3307
[14:05:27.255] Iteration 196: Loss 0.3144
[14:05:28.181] Iteration 197: Loss 0.3103
[14:05:36.990] Iteration 198: Loss 0.2703
[14:05:37.510] Iteration 199: Loss 0.2960
[14:05:38.379] Iteration 200: Loss 0.3444
[14:05:38.895] Iteration 201: Loss 0.2818
[14:05:39.462] Iteration 202: Loss 0.3679
[14:05:39.988] Iteration 203: Loss 0.2427
[14:05:40.506] Iteration 204: Loss 0.3428
[14:05:41.027] Iteration 205: Loss 0.3763
[14:05:57.481] Iteration 206: Loss 0.3037
[14:05:57.995] Iteration 207: Loss 0.3106
[14:05:58.517] Iteration 208: Loss 0.3468
[14:05:59.033] Iteration 209: Loss 0.2939
[14:05:59.549] Iteration 210: Loss 0.2999
[14:06:00.065] Iteration 211: Loss 0.2800
[14:06:00.592] Iteration 212: Loss 0.2891
[14:06:01.111] Iteration 213: Loss 0.3296
[14:06:07.000] Iteration 214: Loss 0.3158
[14:06:07.506] Iteration 215: Loss 0.3182
[14:06:08.044] Iteration 216: Loss 0.2952
[14:06:08.591] Iteration 217: Loss 0.2692
[14:06:09.107] Iteration 218: Loss 0.3041
[14:06:31.506] Iteration 219: Loss 0.3184
[14:06:32.021] Iteration 220: Loss 0.3798
[14:06:32.540] Iteration 221: Loss 0.3498
[14:06:33.055] Iteration 222: Loss 0.3092
[14:06:33.570] Iteration 223: Loss 0.3535
[14:06:34.087] Iteration 224: Loss 0.2987
[14:06:34.598] Iteration 225: Loss 0.3485
[14:06:35.126] Iteration 226: Loss 0.3537
[14:06:46.747] Iteration 227: Loss 0.3132
[14:06:47.260] Iteration 228: Loss 0.3418
[14:06:47.771] Iteration 229: Loss 0.3126
[14:06:48.328] Iteration 230: Loss 0.2985
[14:06:48.917] Iteration 231: Loss 0.3556
[14:06:49.450] Iteration 232: Loss 0.3075
[14:06:50.030] Iteration 233: Loss 0.3296
[14:06:56.177] Iteration 234: Loss 0.2869
[14:06:59.884] Iteration 235: Loss 0.2875
[14:07:00.409] Iteration 236: Loss 0.2939
[14:07:00.937] Iteration 237: Loss 0.2898
[14:07:01.466] Iteration 238: Loss 0.3308
[14:07:02.467] Iteration 239: Loss 0.3451
[14:07:02.984] Iteration 240: Loss 0.2742
[14:07:03.519] Iteration 241: Loss 0.2837
[14:07:22.979] Iteration 242: Loss 0.3347
[14:07:23.498] Iteration 243: Loss 0.3248
[14:07:24.012] Iteration 244: Loss 0.2736
[14:07:24.527] Iteration 245: Loss 0.2811
[14:07:25.045] Iteration 246: Loss 0.3007
[14:07:38.129] Iteration 247: Loss 0.3393
[14:07:38.643] Iteration 248: Loss 0.2619
[14:07:39.161] Iteration 249: Loss 0.3542
[14:07:39.676] Iteration 250: Loss 0.3051
[14:07:40.191] Iteration 251: Loss 0.3308
[14:07:40.706] Iteration 252: Loss 0.3219
[14:07:41.251] Iteration 253: Loss 0.3235
[14:07:41.767] Iteration 254: Loss 0.3490
[14:07:53.209] Iteration 255: Loss 0.2842
[14:07:53.725] Iteration 256: Loss 0.2676
[14:07:54.253] Iteration 257: Loss 0.3083
[14:07:54.771] Iteration 258: Loss 0.3494
[14:02:30.848] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:02:31.382] No checkpoint or best model found. Starting training from scratch.
[14:02:31.384] 18375 iterations per epoch. 50000 total iterations.
[14:06:15.904] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:06:16.406] No checkpoint or best model found. Starting training from scratch.
[14:06:16.408] 18375 iterations per epoch. 50000 total iterations.
[14:08:25.340] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:08:25.882] No checkpoint or best model found. Starting training from scratch.
[14:08:25.884] 18375 iterations per epoch. 50000 total iterations.
[14:13:24.408] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:13:24.995] No checkpoint or best model found. Starting training from scratch.
[14:13:24.997] 18375 iterations per epoch. 50000 total iterations.
[14:18:08.601] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:18:09.632] No checkpoint or best model found. Starting training from scratch.
[14:18:09.637] 18375 iterations per epoch. 50000 total iterations.
[14:22:54.905] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:22:56.027] No checkpoint or best model found. Starting training from scratch.
[14:22:56.028] 18375 iterations per epoch. 50000 total iterations.
[14:27:59.242] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:27:59.649] No checkpoint or best model found. Starting training from scratch.
[14:27:59.650] 18375 iterations per epoch. 50000 total iterations.
[14:31:28.818] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:31:29.261] No checkpoint or best model found. Starting training from scratch.
[14:31:29.262] 18375 iterations per epoch. 50000 total iterations.
[14:31:49.705] Iteration 1: Loss 0.8653
[14:31:53.227] Iteration 2: Loss 0.8223
[14:31:54.041] Iteration 3: Loss 0.7617
[14:31:54.897] Iteration 4: Loss 0.6726
[14:31:55.635] Iteration 5: Loss 0.6070
[14:31:56.400] Iteration 6: Loss 0.5320
[14:31:57.313] Iteration 7: Loss 0.4900
[14:31:58.441] Iteration 8: Loss 0.4550
[14:33:12.670] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:33:13.148] No checkpoint or best model found. Starting training from scratch.
[14:33:13.149] 18375 iterations per epoch. 50000 total iterations.
[14:33:33.581] Iteration 1: Loss 0.8653
[14:33:36.579] Iteration 2: Loss 0.8223
[14:33:37.405] Iteration 3: Loss 0.7618
[14:33:38.222] Iteration 4: Loss 0.6728
[14:33:39.032] Iteration 5: Loss 0.6077
[14:33:39.838] Iteration 6: Loss 0.5332
[14:33:40.681] Iteration 7: Loss 0.4845
[14:33:41.692] Iteration 8: Loss 0.4539
[14:33:58.825] Iteration 9: Loss 0.4204
[14:33:59.713] Iteration 10: Loss 0.3925
[14:34:00.425] Iteration 11: Loss 0.3601
[14:34:01.133] Iteration 12: Loss 0.3849
[14:34:02.007] Iteration 13: Loss 0.3527
[14:34:02.832] Iteration 14: Loss 0.3308
[14:34:03.705] Iteration 15: Loss 0.3780
[14:34:04.629] Iteration 16: Loss 0.3445
[14:34:05.591] Iteration 17: Loss 0.2945
[14:34:06.547] Iteration 18: Loss 0.3500
[14:34:07.477] Iteration 19: Loss 0.3566
[14:34:08.411] Iteration 20: Loss 0.3453
[14:34:09.353] Iteration 21: Loss 0.3597
[14:34:10.416] Iteration 22: Loss 0.3770
[14:34:11.416] Iteration 23: Loss 0.3494
[14:34:12.408] Iteration 24: Loss 0.3324
[14:34:23.754] Iteration 25: Loss 0.3320
[14:34:24.555] Iteration 26: Loss 0.3523
[14:34:25.392] Iteration 27: Loss 0.3523
[14:34:26.262] Iteration 28: Loss 0.3514
[14:34:27.200] Iteration 29: Loss 0.3623
[14:34:28.139] Iteration 30: Loss 0.3318
[14:34:29.212] Iteration 31: Loss 0.3379
[14:34:30.420] Iteration 32: Loss 0.3163
[14:34:40.272] Iteration 33: Loss 0.3385
[14:34:41.404] Iteration 34: Loss 0.3461
[14:34:42.520] Iteration 35: Loss 0.3240
[14:34:47.914] Iteration 36: Loss 0.3437
[14:34:49.510] Iteration 37: Loss 0.3633
[14:34:50.501] Iteration 38: Loss 0.3416
[14:34:51.938] Iteration 39: Loss 0.3206
[14:35:13.504] Iteration 40: Loss 0.3454
[14:35:14.302] Iteration 41: Loss 0.3410
[14:35:15.113] Iteration 42: Loss 0.3576
[14:35:15.977] Iteration 43: Loss 0.3695
[14:35:29.524] Iteration 44: Loss 0.3671
[14:35:30.523] Iteration 45: Loss 0.3362
[14:35:34.701] Iteration 46: Loss 0.3114
[14:35:35.689] Iteration 47: Loss 0.3238
[14:35:36.717] Iteration 48: Loss 0.3248
[14:35:37.789] Iteration 49: Loss 0.3630
[14:35:38.713] Iteration 50: Loss 0.3301
[14:35:39.632] Iteration 51: Loss 0.3043
[14:35:54.710] Iteration 52: Loss 0.3260
[14:35:55.758] Iteration 53: Loss 0.3964
[14:36:02.903] Iteration 54: Loss 0.3414
[14:36:03.874] Iteration 55: Loss 0.3109
[14:36:04.896] Iteration 56: Loss 0.3145
[14:36:05.856] Iteration 57: Loss 0.3635
[14:36:06.995] Iteration 58: Loss 0.3272
[14:36:07.945] Iteration 59: Loss 0.3623
[14:36:21.197] Iteration 60: Loss 0.3113
[14:36:22.008] Iteration 61: Loss 0.3544
[14:38:07.997] Namespace(root_path='kits19/data', list_dir='./lists_kits19', dataset='KiTS19', num_classes=3, max_iterations=50000, max_epochs=150, batch_size=4, n_gpu=1, deterministic=1, base_lr=0.01, img_size=224, seed=1234, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, checkpoint_dir='./checkpoints_kits1', use_attention=1, exp='TU_KiTS19_224')
[14:38:08.647] No checkpoint or best model found. Starting training from scratch.
[14:38:08.649] 18375 iterations per epoch. 50000 total iterations.
[14:38:26.767] Iteration 1: Loss 0.8653
[14:38:29.227] Iteration 2: Loss 0.8223
[14:38:30.063] Iteration 3: Loss 0.7617
[14:38:30.968] Iteration 4: Loss 0.6722
[14:38:31.849] Iteration 5: Loss 0.6071
[14:38:32.834] Iteration 6: Loss 0.5336
[14:38:33.572] Iteration 7: Loss 0.4891
[14:38:34.716] Iteration 8: Loss 0.4545
[14:38:47.183] Iteration 9: Loss 0.4173
[14:38:47.976] Iteration 10: Loss 0.4019
[14:38:48.341] Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[14:38:48.341] NumExpr defaulting to 8 threads.
[14:38:49.926] Iteration 11: Loss 0.3788
[14:38:50.622] Iteration 12: Loss 0.3892
[14:38:51.337] Iteration 13: Loss 0.3477
[14:38:52.115] Iteration 14: Loss 0.3809
[14:38:52.978] Iteration 15: Loss 0.3699
[14:38:53.852] Iteration 16: Loss 0.3632
[14:38:54.688] Iteration 17: Loss 0.3276
[14:38:55.563] Iteration 18: Loss 0.3480
[14:38:56.445] Iteration 19: Loss 0.3464
[14:38:57.541] Iteration 20: Loss 0.3616
[14:38:58.594] Iteration 21: Loss 0.3615
[14:38:59.848] Iteration 22: Loss 0.3349
[14:39:01.274] Iteration 23: Loss 0.3589
[14:39:02.375] Iteration 24: Loss 0.3420
[14:39:13.033] Iteration 25: Loss 0.3347
[14:39:14.001] Iteration 26: Loss 0.3697
[14:39:15.014] Iteration 27: Loss 0.3465
[14:39:16.379] Iteration 28: Loss 0.3447
[14:39:19.364] Iteration 29: Loss 0.3383
[14:39:20.440] Iteration 30: Loss 0.3526
[14:39:21.542] Iteration 31: Loss 0.3252
[14:39:24.178] Iteration 32: Loss 0.3409
[14:39:29.049] Iteration 33: Loss 0.3439
[14:39:30.005] Iteration 34: Loss 0.3376
[14:39:30.991] Iteration 35: Loss 0.3142
[14:39:38.082] Iteration 36: Loss 0.3677
[14:39:41.079] Iteration 37: Loss 0.3503
[14:39:42.177] Iteration 38: Loss 0.3609
[14:39:43.117] Iteration 39: Loss 0.3650
[14:40:01.640] Iteration 40: Loss 0.3458
[14:40:02.681] Iteration 41: Loss 0.3392
[14:40:03.537] Iteration 42: Loss 0.3705
[14:40:04.477] Iteration 43: Loss 0.4111
[14:40:12.012] Iteration 44: Loss 0.4054
[14:40:12.853] Iteration 45: Loss 0.3335
[14:40:22.695] Iteration 46: Loss 0.3241
[14:40:23.618] Iteration 47: Loss 0.3355
[14:40:24.530] Iteration 48: Loss 0.3478
[14:40:25.581] Iteration 49: Loss 0.3594
[14:40:26.514] Iteration 50: Loss 0.3331
[14:40:27.457] Iteration 51: Loss 0.3392
[14:40:35.423] Iteration 52: Loss 0.3196
[14:40:36.277] Iteration 53: Loss 0.3578
[14:40:45.286] Iteration 54: Loss 0.3137
[14:40:46.234] Iteration 55: Loss 0.3035
[14:40:47.087] Iteration 56: Loss 0.3023
[14:40:47.941] Iteration 57: Loss 0.3598
[14:40:48.824] Iteration 58: Loss 0.3261
[14:40:49.761] Iteration 59: Loss 0.3650
